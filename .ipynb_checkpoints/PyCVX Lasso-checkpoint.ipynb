{
 "metadata": {
  "name": "",
  "signature": "sha256:79c5fb09e5be0578fcfdd2c2e85c20eb91b0e80706bdc28f4c1a986f0809f0fa"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "###################################################################\n",
      "# Creates a term document matrix from movie reviews data          #\n",
      "###################################################################\n",
      "import sys\n",
      "import os\n",
      "import glob\n",
      "import numpy as np\n",
      "from sklearn.feature_extraction.text import TfidfVectorizer\n",
      "\n",
      "START_K = 0\n",
      "K = 1000\n",
      "\n",
      "# Movie data corpus\n",
      "negative_files = glob.glob(\"movie_review_data/neg/*.txt\")\n",
      "positive_files = glob.glob(\"movie_review_data/pos/*.txt\")\n",
      "all_file_names = negative_files + positive_files\n",
      "\n",
      "# Load valid english words\n",
      "valid_words = set()\n",
      "dictionary_file = open(\"words\")\n",
      "for word in dictionary_file:\n",
      "    word = word.lower().strip()\n",
      "    valid_words.add(word)\n",
      "    \n",
      "# Load english stop words\n",
      "stop_words = set()\n",
      "stop_words_file = open(\"stop_words\")\n",
      "for word in stop_words_file:\n",
      "    word = word.lower().strip()\n",
      "    stop_words.add(word)\n",
      "\n",
      "# Filter even more. Only take the K top most frequent words from the combined corpus\n",
      "word_frequencies = {}\n",
      "corpus_words = set()\n",
      "for file_name in all_file_names:\n",
      "    f = open(file_name)\n",
      "    text = unicode(f.read(), 'latin-1')\n",
      "    for word in text.split(\" \"):\n",
      "        word = word.lower().strip()\n",
      "        if word in valid_words and word not in stop_words:\n",
      "            if word not in word_frequencies:\n",
      "                word_frequencies[word] = 0\n",
      "            word_frequencies[word] += 1\n",
      "            corpus_words.add(word)\n",
      "    f.close()\n",
      "valid_features = sorted(corpus_words, key=lambda x: word_frequencies[x], reverse=True)[START_K:START_K+K]\n",
      "                \n",
      "# Collect all movie review text (both positive and negatively sentimented)\n",
      "corpus = []\n",
      "for count, file_name in enumerate(all_file_names):\n",
      "    f = open(file_name)\n",
      "    document_string = unicode(f.read(), 'latin-1')\n",
      "    filtered_document_string = \"\"\n",
      "    for word in document_string.split(\" \"):\n",
      "        word = word.lower().strip()\n",
      "        if word in valid_features:\n",
      "            filtered_document_string += word + ' '\n",
      "    corpus.append(filtered_document_string)\n",
      "    f.close()\n",
      "print(\"Done creating corpus!\")\n",
      "\n",
      "# Use Sklearn to get the term document matrix\n",
      "vectorizer = TfidfVectorizer(min_df=1, stop_words=\"english\")\n",
      "term_doc_matrix = vectorizer.fit_transform(corpus)\n",
      "\n",
      "# tdm and features\n",
      "tdm = term_doc_matrix.toarray()\n",
      "features = vectorizer.get_feature_names()\n",
      "\n",
      "print(\"Number of rows: %d cols: %d\" % tdm.shape)\n",
      "print(tdm)\n",
      "print(\"Features:\")\n",
      "print(features)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Done creating corpus!\n",
        "Number of rows: 20 cols: 972\n",
        "[[ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
        " [ 0.          0.          0.04881376 ...,  0.          0.          0.03281215]\n",
        " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
        " ..., \n",
        " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
        " [ 0.          0.          0.         ...,  0.05039032  0.          0.03853391]\n",
        " [ 0.          0.          0.         ...,  0.          0.          0.03549527]]\n",
        "Features:\n",
        "[u'absent', u'academic', u'accident', u'accused', u'achievement', u'act', u'acting', u'action', u'actor', u'actually', u'add', u'added', u'adore', u'adult', u'advantage', u'affinity', u'afraid', u'age', u'agent', u'ago', u'aide', u'aim', u'airy', u'al', u'alice', u'alternately', u'altogether', u'amazingly', u'ambitious', u'american', u'amusing', u'amy', u'analysis', u'ancestral', u'ancient', u'anderson', u'angry', u'anna', u'annette', u'annoying', u'anonymous', u'answer', u'antagonism', u'aplomb', u'apparent', u'apparently', u'appealing', u'appear', u'archive', u'arms', u'artificial', u'aside', u'asleep', u'aspect', u'assessment', u'assured', u'attempt', u'attention', u'attract', u'audience', u'awake', u'award', u'awful', u'awhile', u'awry', u'baby', u'bad', u'badly', u'bait', u'bandstand', u'based', u'bathroom', u'bathtub', u'batman', u'battlefield', u'bear', u'bed', u'beef', u'believe', u'bell', u'beloved', u'betty', u'billie', u'birth', u'bit', u'bitter', u'black', u'blair', u'bland', u'blatantly', u'bleak', u'blindness', u'bliss', u'blood', u'blown', u'blue', u'board', u'boardman', u'bobby', u'body', u'book', u'boring', u'born', u'boss', u'boston', u'bound', u'boy', u'break', u'breakdown', u'brief', u'brilliance', u'brooding', u'brooke', u'budget', u'bunch', u'bureaucratic', u'burnt', u'calling', u'calvinist', u'camera', u'camp', u'campaign', u'car', u'care', u'career', u'cash', u'cast', u'casting', u'catch', u'catholic', u'cathy', u'cause', u'celebration', u'chair', u'chance', u'character', u'charisma', u'chase', u'cheap', u'checker', u'cheesiness', u'chief', u'child', u'childhood', u'christmas', u'chubby', u'cinematic', u'city', u'clarification', u'clark', u'classic', u'cliche', u'climax', u'cloak', u'club', u'colorful', u'columbia', u'combination', u'comedic', u'comedy', u'comes', u'comeuppance', u'comic', u'coming', u'compassion', u'complete', u'completely', u'complex', u'compliment', u'conclusion', u'condition', u'conditioned', u'confrontation', u'confusion', u'connection', u'considered', u'constantly', u'contact', u'continually', u'continue', u'continuity', u'convinced', u'corny', u'costuming', u'country', u'county', u'couple', u'course', u'covering', u'crap', u'crazy', u'creepy', u'crew', u'crisis', u'critic', u'crock', u'cruel', u'crush', u'cultural', u'culture', u'cut', u'daddy', u'damme', u'dance', u'dancing', u'daniel', u'danny', u'darby', u'dark', u'dating', u'daughter', u'dave', u'david', u'day', u'days', u'dead', u'deal', u'dealer', u'death', u'debi', u'debut', u'decided', u'delight', u'democrat', u'denis', u'dennis', u'depend', u'description', u'despite', u'devoted', u'dialogue', u'diane', u'diaphragm', u'dice', u'dick', u'dig', u'digital', u'directed', u'director', u'dirty', u'disaster', u'discovery', u'disjointed', u'displeasure', u'distinction', u'disturbed', u'disturbing', u'ditch', u'documentary', u'dog', u'dogs', u'doing', u'domestically', u'dora', u'double', u'doubt', u'dour', u'downright', u'drama', u'dramatic', u'drive', u'driver', u'driving', u'drop', u'drunk', u'dumb', u'eagerly', u'earth', u'easier', u'easy', u'edward', u'effects', u'elaine', u'elegant', u'elisabeth', u'emotional', u'encounter', u'encourage', u'enjoy', u'enjoyable', u'enter', u'entertaining', u'environment', u'epilogue', u'erratically', u'especially', u'essentially', u'established', u'ethics', u'european', u'event', u'eventually', u'evil', u'example', u'excellent', u'exception', u'excited', u'exist', u'existence', u'experience', u'expression', u'extent', u'exterior', u'extremely', u'exuberantly', u'factual', u'fake', u'fall', u'familiar', u'family', u'famous', u'fan', u'faraday', u'fascinating', u'fashion', u'fast', u'fate', u'favorite', u'feature', u'feel', u'fencing', u'fictional', u'figure', u'film', u'final', u'finale', u'fine', u'finish', u'flanked', u'flashy', u'flat', u'float', u'floor', u'flow', u'following', u'footage', u'forget', u'form', u'forte', u'foster', u'fragile', u'frankly', u'free', u'frenetic', u'friend', u'friendly', u'fugitive', u'fun', u'funny', u'future', u'gamble', u'gathering', u'genre', u'genuine', u'george', u'gerard', u'geriatric', u'getting', u'ghoul', u'gimmick', u'girl', u'glaring', u'glitter', u'goat', u'god', u'goes', u'golden', u'gone', u'goth', u'grader', u'graduate', u'grandfather', u'grandmother', u'grant', u'gratification', u'green', u'greg', u'gruesomely', u'guess', u'guessing', u'guidance', u'guilty', u'guy', u'guzzle', u'hair', u'hal', u'hand', u'hank', u'happen', u'happy', u'hard', u'harris', u'hat', u'hate', u'head', u'headed', u'hear', u'heavily', u'helen', u'hell', u'hero', u'hidden', u'hide', u'highly', u'hill', u'history', u'hit', u'hold', u'hole', u'hollywood', u'home', u'hope', u'horrendous', u'horror', u'horse', u'hospital', u'hot', u'hotel', u'hour', u'house', u'howl', u'huge', u'human', u'humanity', u'humor', u'hunt', u'hush', u'idea', u'idiot', u'idiotic', u'ignorance', u'ill', u'illustrate', u'impossible', u'improbable', u'incompetent', u'increase', u'independent', u'indiana', u'indulge', u'infinitely', u'influential', u'information', u'informative', u'innuendo', u'inside', u'installment', u'instance', u'instant', u'instead', u'instructional', u'intellect', u'interrupted', u'invasion', u'involved', u'irish', u'item', u'jack', u'jackson', u'jacob', u'james', u'jamie', u'jan', u'jane', u'jason', u'jay', u'jealous', u'jeff', u'jennifer', u'jessica', u'joan', u'john', u'johnathan', u'join', u'jonathan', u'jones', u'joseph', u'joshua', u'journey', u'juggling', u'kate', u'kathleen', u'kathryn', u'keeping', u'kept', u'kidnap', u'kids', u'kill', u'killer', u'kurt', u'lack', u'lame', u'language', u'larry', u'late', u'laugh', u'laughable', u'laughing', u'lay', u'lazy', u'lead', u'leads', u'learned', u'leave', u'leaves', u'leaving', u'lee', u'left', u'legend', u'level', u'lewis', u'life', u'lift', u'line', u'lisa', u'list', u'little', u'live', u'locked', u'lodge', u'loggia', u'lonely', u'look', u'looking', u'lorry', u'loser', u'lost', u'lot', u'lots', u'loud', u'lounge', u'love', u'lucky', u'luggage', u'luke', u'major', u'manipulative', u'mann', u'manner', u'manor', u'mansion', u'marie', u'mark', u'marketing', u'marrow', u'marsha', u'marshal', u'marshall', u'martha', u'mason', u'master', u'match', u'matchmaker', u'material', u'matter', u'maureen', u'maybe', u'mean', u'meat', u'meet', u'mental', u'mention', u'merely', u'mess', u'message', u'met', u'michael', u'mickey', u'middle', u'mildly', u'millennium', u'millie', u'million', u'milo', u'misguided', u'mistake', u'moderately', u'modern', u'moment', u'money', u'monkey', u'moral', u'mother', u'motion', u'mouth', u'movie', u'mud', u'murder', u'murphy', u'music', u'musical', u'narcotic', u'negative', u'nell', u'net', u'network', u'newspaper', u'nice', u'niche', u'night', u'nina', u'norm', u'normal', u'normally', u'nostalgic', u'novel', u'nude', u'nudity', u'nurse', u'obnoxious', u'offer', u'office', u'oh', u'oliver', u'opportunity', u'organized', u'origin', u'original', u'oscar', u'overall', u'overcome', u'page', u'pain', u'paranoid', u'parsley', u'pathetic', u'paul', u'peck', u'people', u'perfectly', u'period', u'person', u'persona', u'peter', u'phone', u'photogenic', u'photography', u'pick', u'picture', u'piece', u'pilgrim', u'piss', u'play', u'pleasure', u'plenty', u'plot', u'plus', u'pointless', u'political', u'poorly', u'pop', u'popular', u'possessed', u'possibly', u'praying', u'preceding', u'predictable', u'predictably', u'pregnant', u'prepared', u'presidency', u'presumably', u'pretty', u'previous', u'privilege', u'prize', u'probably', u'produced', u'production', u'professor', u'project', u'promise', u'protracted', u'psychological', u'pull', u'quest', u'question', u'quick', u'quickly', u'radio', u'ramble', u'random', u'rapidly', u'rated', u'read', u'real', u'reality', u'realize', u'realizing', u'reason', u'received', u'recommend', u'record', u'recording', u'recovery', u'recuperate', u'red', u'reel', u'reese', u'regardless', u'regular', u'relationship', u'release', u'religious', u'removed', u'reputation', u'reputedly', u'rescue', u'researcher', u'reserve', u'reset', u'respectable', u'response', u'rest', u'result', u'revenge', u'review', u'rich', u'ricky', u'ringer', u'risk', u'road', u'robert', u'rock', u'rod', u'rodman', u'roger', u'role', u'roll', u'roller', u'roman', u'rome', u'romp', u'ron', u'rosemary', u'rough', u'run', u'running', u'russell', u'rusty', u'ryder', u'sadly', u'sage', u'sam', u'sanitary', u'sarah', u'satyr', u'save', u'saved', u'saying', u'scare', u'scary', u'scene', u'scenery', u'school', u'schooling', u'score', u'scream', u'screaming', u'screen', u'screening', u'screenplay', u'screwed', u'script', u'sebastian', u'section', u'security', u'seeing', u'seemingly', u'seen', u'senator', u'send', u'sense', u'series', u'set', u'settle', u'sexual', u'sexuality', u'shadow', u'shaking', u'share', u'shipped', u'short', u'shot', u'shout', u'sign', u'similar', u'simply', u'singer', u'sitting', u'skit', u'slasher', u'sleep', u'slightly', u'slowly', u'smalls', u'smell', u'smile', u'social', u'somewhat', u'son', u'song', u'soon', u'sound', u'spencer', u'spend', u'spew', u'spice', u'spoken', u'spooky', u'staggers', u'star', u'starring', u'start', u'starting', u'stay', u'stays', u'stephanie', u'stepping', u'stereotypical', u'story', u'strange', u'strangely', u'strategist', u'street', u'strong', u'stuck', u'study', u'stuffed', u'stumble', u'stupid', u'stupidity', u'style', u'subject', u'succeeding', u'successful', u'succession', u'succumb', u'suddenly', u'sue', u'suffer', u'suggest', u'suggestive', u'suicide', u'support', u'supposed', u'supposedly', u'surprise', u'surprising', u'susanna', u'talent', u'talking', u'tank', u'target', u'taylor', u'teacher', u'team', u'television', u'tell', u'terrible', u'terrorism', u'theater', u'theme', u'theo', u'thesis', u'thinking', u'thirty', u'thoroughly', u'thriller', u'thyme', u'till', u'tim', u'time', u'times', u'timothy', u'tiny', u'tired', u'title', u'told', u'tolerable', u'tolerate', u'tom', u'tommy', u'total', u'tough', u'town', u'traditional', u'training', u'transform', u'travel', u'trickery', u'tried', u'trio', u'trouble', u'truck', u'true', u'try', u'trying', u'tune', u'twist', u'ultimately', u'unbelievably', u'uncomfortable', u'unexplained', u'unfortunate', u'unfortunately', u'uniformly', u'unique', u'unit', u'university', u'unless', u'unmistakable', u'unrelated', u'urban', u'vaguely', u'value', u'van', u'vapidly', u'various', u'vast', u'venue', u'victory', u'villain', u'violence', u'visible', u'visit', u'vodka', u'voice', u'wacky', u'walsh', u'war', u'warner', u'warren', u'waste', u'wasted', u'watch', u'watched', u'watching', u'water', u'weak', u'wealthy', u'wear', u'weird', u'welcome', u'whatsoever', u'whip', u'whit', u'white', u'whoops', u'wide', u'wife', u'wilson', u'wing', u'wink', u'winona', u'wisdom', u'wise', u'wish', u'witch', u'witty', u'woman', u'wondering', u'word', u'world', u'worse', u'worst', u'worth', u'written', u'wrong', u'yell', u'yelling', u'york']\n"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "###################################################################\n",
      "# Searches query term within list of corpus                       #\n",
      "###################################################################\n",
      "\n",
      "query = unicode('plot')\n",
      "query_presence_indicators = []\n",
      "\n",
      "# Create the indicator column\n",
      "if query in features:\n",
      "    location_in_matrix = features.index(query)\n",
      "    features.remove(query)\n",
      "    \n",
      "    # Remove column with query term from tdm\n",
      "    tdm = np.delete(tdm, location_in_matrix, axis=1)\n",
      "    \n",
      "    # Construct indicator vector\n",
      "    for document in tdm:\n",
      "        if document[location_in_matrix] != 0:\n",
      "            query_presence_indicators.append(1)\n",
      "        else:\n",
      "            query_presence_indicators.append(-1)\n",
      "else:\n",
      "    print(\"Query not found\")\n",
      "\n",
      "print(\"Number of documents\", len(query_presence_indicators))\n",
      "print(\"Number of times query appears in all documents: \", sum([1 if x == 1 else 0 for x in query_presence_indicators]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "('Number of documents', 20)\n",
        "('Number of times query appears in all documents: ', 2)\n"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from cvxpy import *\n",
      "import numpy as np\n",
      "import cvxopt\n",
      "from multiprocessing import Pool\n",
      "\n",
      "# Problem data.\n",
      "A = tdm\n",
      "b = query_presence_indicators\n",
      "gamma = Parameter(sign=\"positive\")\n",
      "\n",
      "# Construct the problem.\n",
      "x = Variable(len(A[0]))\n",
      "objective = Minimize(sum_squares(A*x - b) + gamma*norm(x, 1))\n",
      "p = Problem(objective)\n",
      "\n",
      "# Assign a value to gamma and find the optimal x.\n",
      "def get_x(gamma_value):\n",
      "    gamma.value = gamma_value\n",
      "    result = p.solve()\n",
      "    return x.value\n",
      "\n",
      "gammas = np.logspace(-1, 2, num=10)\n",
      "\n",
      "# Parallel computation.\n",
      "print(\"Starting computation\")\n",
      "pool = Pool(processes=1)\n",
      "x_values = pool.map(get_x, gammas)\n",
      "\n",
      "# Serial computation.\n",
      "lasso_weights = [get_x(value) for value in gammas]\n",
      "\n",
      "for v1,v2 in zip(x_values, lasso_weights):\n",
      "    if np.linalg.norm(v1 - v2) > 1e-5:\n",
      "        print \"error\"\n",
      "        \n",
      "print(\"Done!\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Starting computation\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Done!\n"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Copyright (c) 2014 Steve Yadlowsky, Preetum Nakkarin.\n",
      "# Licensed under MIT License.\n",
      "# More information including the exact terms of the License\n",
      "# can be found in the file COPYING in the project root directory.\n",
      "\n",
      "import numpy as np\n",
      "import time\n",
      "import operator\n",
      "import scipy.sparse\n",
      "\n",
      "class IHTClassifier(object):\n",
      "    \n",
      "    def __init__(self):\n",
      "        self.training_time = 0.0\n",
      "        self.beta = None\n",
      "\n",
      "    def card(self, x):\n",
      "        return np.sum(x != 0)\n",
      "\n",
      "    def train(self, X, y, card=100, verbose=False):\n",
      "        start = time.time()\n",
      "        if verbose:\n",
      "            print \"Preconditioning matrix\"\n",
      "        whitened_X, feature_avg = self.whiten_features(X)\n",
      "        lsv = float(self.compute_lsv(whitened_X, feature_avg))\n",
      "        if verbose:\n",
      "            print \"Matching pursuits\"\n",
      "        x_hat = self.matching_pursuit_sparse(y, whitened_X/lsv, feature_avg/lsv, card)\n",
      "        if verbose:\n",
      "            print \"Running iterative hard thresholding\"\n",
      "        self.beta = self.AIHT_sparse(y, whitened_X/lsv, x_hat, card, feature_avg/lsv)/lsv\n",
      "\n",
      "        self.training_time += time.time() - start\n",
      "\n",
      "    def whiten_features(self, X):\n",
      "        X = X.tocsr(copy=True)\n",
      "        row_avg = np.bincount(X.indices, weights=X.data)\n",
      "        row_avg /= float(X.shape[0])\n",
      "        row_norm = np.bincount(X.indices, weights=(X.data - row_avg[X.indices])**2)\n",
      "        nonzeros_in_each_column = np.diff(X.tocsc().indptr)\n",
      "        avg_norm = ((float(X.shape[0])*np.ones(X.shape[1])) - nonzeros_in_each_column)*(row_avg**2)\n",
      "        row_norm += avg_norm\n",
      "        row_norm = np.array([np.sqrt(x) if x != 0 else 1 for x in row_norm])\n",
      "        row_avg /= row_norm\n",
      "        X.data /= np.take(row_norm, X.indices)\n",
      "        feature_avg = np.squeeze(row_avg)\n",
      "\n",
      "        return X, feature_avg\n",
      "\n",
      "    def compute_lsv(self, X, feature_avg):\n",
      "        def matmuldyad(v):\n",
      "            return X.dot(v) - feature_avg.dot(v)\n",
      "\n",
      "        def rmatmuldyad(v):\n",
      "            return X.T.dot(v) - v.sum()*feature_avg\n",
      "        normalized_lin_op = scipy.sparse.linalg.LinearOperator(X.shape, matmuldyad, rmatmuldyad)\n",
      "\n",
      "        def matvec_XH_X(v):\n",
      "            return normalized_lin_op.rmatvec(normalized_lin_op.matvec(v))\n",
      "\n",
      "        which='LM'\n",
      "        v0=None\n",
      "        maxiter=None\n",
      "        return_singular_vectors=False\n",
      "\n",
      "        XH_X = scipy.sparse.linalg.LinearOperator(matvec=matvec_XH_X, dtype=X.dtype, shape=(X.shape[1], X.shape[1]))\n",
      "        eigvals = scipy.sparse.linalg.eigs(XH_X, k=1, tol=0, maxiter=None, ncv=10, which=which, v0=v0, return_eigenvectors=False)\n",
      "        lsv = np.sqrt(eigvals)\n",
      "        return lsv[0].real\n",
      "\n",
      "    def matching_pursuit_sparse(self, y, X, feature_avg, k, tol=10**-10):\n",
      "        '''\n",
      "        Matching Pursuit\n",
      "        '''\n",
      "        r = y\n",
      "        X = X.tocsc()\n",
      "        err_norm = np.linalg.norm(r, 2)\n",
      "        err_norm_prev = 0\n",
      "        beta = np.zeros(X.shape[1])\n",
      "        while self.card(beta) < k:\n",
      "            all_inner_products = X.T.dot(r) - np.sum(r)*feature_avg\n",
      "            max_index, max_abs_inner_product = max(enumerate(np.abs(all_inner_products)), key=operator.itemgetter(1))\n",
      "            g = X[:, max_index]\n",
      "            g = np.squeeze(np.asarray(g.todense())) - feature_avg[max_index]\n",
      "            a = all_inner_products[max_index]\n",
      "            a /= np.linalg.norm(g, 2)**2\n",
      "            beta[max_index] += a\n",
      "            r = r - a*g\n",
      "            err_norm_prev = err_norm\n",
      "            err_norm = np.linalg.norm(r, 2)\n",
      "            if np.abs(err_norm - err_norm_prev) <= tol:\n",
      "                break\n",
      "        return beta\n",
      "\n",
      "    def thresholder(self, y,m):\n",
      "        sort_y = sorted(np.abs(y))\n",
      "        thresh = sort_y[-m]\n",
      "\n",
      "        non_thresholded_indices = (np.abs(y) > thresh)\n",
      "        n_nonzero_indices = sum(non_thresholded_indices)\n",
      "        if n_nonzero_indices < m:\n",
      "            collisions = np.where((np.abs(y)==thresh))[0]\n",
      "            passed = np.random.choice(collisions,m-n_nonzero_indices)\n",
      "            non_thresholded_indices[passed] = 1\n",
      "\n",
      "        y_new = non_thresholded_indices * y\n",
      "\n",
      "        return y_new, thresh\n",
      "\n",
      "    def AIHT_sparse(self, y, X, beta, k, feature_avg=None, alpha=0, example_weights=None, max_iters=10000, tol=10**-16):\n",
      "        \"\"\"Solves DORE accelerated IHT with a sparse matrix X.\n",
      "        \"\"\"\n",
      "        m, n = X.shape\n",
      "        y = np.squeeze(np.asarray(y))\n",
      "        err_norm_prev = 0\n",
      "        beta_0 = beta\n",
      "        beta_prev = beta\n",
      "        X_beta = 0\n",
      "        X_beta_prev = 0\n",
      "        X_beta_twice_prev = 0\n",
      "\n",
      "        if feature_avg is None:\n",
      "            feature_avg = np.zeros(n)\n",
      "    \n",
      "        if example_weights is None:\n",
      "            example_weights = np.ones(m)\n",
      "    \n",
      "        for iter_ in xrange(max_iters):\n",
      "            X_beta_twice_prev = X_beta_prev\n",
      "            X_beta_prev = X_beta\n",
      "            X_beta = (X.dot(beta) - feature_avg.dot(beta))\n",
      "            X_beta = np.squeeze(np.asarray(X_beta))\n",
      "            err = y - example_weights*X_beta\n",
      "            err_reg = -alpha*beta\n",
      "            norm_change = ((np.linalg.norm(beta - beta_prev)**2)/n)\n",
      "            print err.dot(err) + err_reg.dot(err_reg), norm_change, np.linalg.norm(beta)\n",
      "\n",
      "            if iter_ > 0 and (norm_change <= tol):\n",
      "                break\n",
      "\n",
      "            beta_t = beta + np.squeeze(np.asarray(X.T.dot(err))) - err.sum()*feature_avg + alpha*err_reg\n",
      "            beta_t = np.squeeze(np.asarray(beta_t))\n",
      "    \n",
      "            beta_t, thresh = self.thresholder(beta_t,k)\n",
      "            X_beta = X.dot(beta_t) - feature_avg.dot(beta_t)\n",
      "            X_beta = np.squeeze(X_beta)\n",
      "            err = y - example_weights*X_beta\n",
      "            err_reg = -alpha*beta_t\n",
      "    \n",
      "            beta_t_star = beta_t\n",
      "            if iter_ > 2:\n",
      "                delta_X_beta = X_beta - X_beta_prev\n",
      "                delta_regularization = alpha*(beta_t - beta)\n",
      "                dp = delta_X_beta.dot(example_weights*delta_X_beta) + delta_regularization.dot(delta_regularization)\n",
      "                if dp > 0:\n",
      "                    a1 = (delta_X_beta.dot(err) + delta_regularization.dot(err_reg))/dp\n",
      "                    X_beta_1 = (1+a1)*X_beta - a1*X_beta_prev\n",
      "                    beta_1 = beta_t + a1*(beta_t - beta)\n",
      "                    err_1 = y - example_weights*X_beta_1\n",
      "                    err_1_reg = -alpha*beta_1\n",
      "    \n",
      "                    delta_X_beta = X_beta_1 - X_beta_twice_prev\n",
      "                    delta_regularization = alpha*(beta_1 - beta_prev)\n",
      "                    dp = delta_X_beta.dot(example_weights*delta_X_beta) + delta_regularization.dot(delta_regularization)\n",
      "                    if dp > 0:\n",
      "                        a2 = (delta_X_beta.dot(err_1) + delta_regularization.dot(err_1_reg))/dp\n",
      "                        beta_2 = beta_1 + a2*(beta_1 - beta_prev)\n",
      "                        beta_2, thresh = self.thresholder(beta_2,k)\n",
      "    \n",
      "                        X_beta_2 = X.dot(beta_2) - feature_avg.dot(beta_2)\n",
      "                        X_beta_2 = np.squeeze(np.asarray(X_beta_2))\n",
      "                        err_2 = y - example_weights*X_beta_2\n",
      "                        err_reg_2 = -alpha*beta_2\n",
      "    \n",
      "                        if (err_2.dot(err_2) + err_reg_2.dot(err_reg_2)) / (err.dot(err) + err_reg.dot(err_reg)) < 1:\n",
      "                            beta_t_star = beta_2\n",
      "                            X_beta = X_beta_2\n",
      "    \n",
      "            beta_prev = beta\n",
      "            beta = beta_t_star\n",
      "    \n",
      "        return beta"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "IHT_weights = []\n",
      "print(len(b))\n",
      "print(A.shape)\n",
      "for card in range(10, 200, 3):\n",
      "    classifier = IHTClassifier()\n",
      "    sparse_matrix = scipy.sparse.csr_matrix(A)\n",
      "    classifier.train(sparse_matrix, b, verbose=True, card=card)\n",
      "    IHT_weights.append(classifier.beta)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "20\n",
        "(20, 971)\n",
        "Preconditioning matrix\n",
        "('ROWAVG: ', (971,))\n",
        "('X: ', (20, 971))\n",
        "Matching pursuits\n",
        "Running iterative hard thresholding\n",
        "12.8 0.0 23.4965768165\n",
        "12.8 1.7861201455e-18 23.4965768053\n",
        "Preconditioning matrix\n",
        "('ROWAVG: ', (971,))\n",
        "('X: ', (20, 971))\n",
        "Matching pursuits\n",
        "Running iterative hard thresholding"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "12.8 0.0 23.4965768165\n",
        "12.8 2.5233848561e-18 23.4965768053\n",
        "Preconditioning matrix\n",
        "('ROWAVG: ', (971,))\n",
        "('X: ', (20, 971))\n",
        "Matching pursuits\n",
        "Running iterative hard thresholding\n",
        "12.8 0.0 23.4965740077\n",
        "12.8 3.26064957177e-18 23.4965739965\n",
        "Preconditioning matrix\n",
        "('ROWAVG: ', (971,))\n",
        "('X: ', (20, 971))\n",
        "Matching pursuits\n",
        "Running iterative hard thresholding"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "12.8 0.0 23.4965768165\n",
        "12.8 3.75215937231e-18 23.4965768053\n",
        "Preconditioning matrix\n",
        "('ROWAVG: ', (971,))\n",
        "('X: ', (20, 971))\n",
        "Matching pursuits\n",
        "Running iterative hard thresholding\n",
        "12.8 0.0 23.4965768165\n",
        "12.8 3.99791427466e-18 23.4965768053\n",
        "Preconditioning matrix\n",
        "('ROWAVG: ', (971,))\n",
        "('X: ', (20, 971))\n",
        "Matching pursuits\n",
        "Running iterative hard thresholding\n",
        "12.8 0.0 23.4603258953\n",
        "12.8 4.98093390485e-18 23.4603258841\n",
        "Preconditioning matrix\n",
        "('ROWAVG: ', (971,))\n",
        "('X: ', (20, 971))\n",
        "Matching pursuits"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Running iterative hard thresholding\n",
        "12.8 0.0 23.4965768165\n",
        "12.8 4.73517899277e-18 23.4965768053\n",
        "Preconditioning matrix\n",
        "('ROWAVG: ', (971,))\n",
        "('X: ', (20, 971))\n",
        "Matching pursuits\n",
        "Running iterative hard thresholding\n",
        "12.8 0.0 23.4965768165\n",
        "12.8 4.73517898527e-18 23.4965768053\n",
        "Preconditioning matrix\n",
        "('ROWAVG: ', (971,))\n",
        "('X: ', (20, 971))\n",
        "Matching pursuits\n",
        "Running iterative hard thresholding\n",
        "12.8 0.0 23.4965768165\n",
        "12.8"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 7.92999274108e-18 23.4965768053\n",
        "Preconditioning matrix\n",
        "('ROWAVG: ', (971,))\n",
        "('X: ', (20, 971))\n",
        "Matching pursuits\n",
        "Running iterative hard thresholding\n",
        "12.8 0.0 23.4965768165\n",
        "12.8 8.46139841167e-18 23.4965768053\n",
        "Preconditioning matrix\n",
        "('ROWAVG: ', (971,))\n",
        "('X: ', (20, 971))\n",
        "Matching pursuits\n",
        "Running iterative hard thresholding\n",
        "12.8 0.0 23.4965768165\n",
        "12.8 8.76419185224e-18 23.4965768053\n",
        "Preconditioning matrix\n",
        "('ROWAVG: ', (971,))\n",
        "('X: ', (20, 971))\n",
        "Matching pursuits\n",
        "Running iterative hard thresholding"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "12.8 0.0 23.4965768165\n",
        "12.8 9.35041230942e-18 23.4965768053\n",
        "Preconditioning matrix\n",
        "('ROWAVG: ', (971,))\n",
        "('X: ', (20, 971))\n",
        "Matching pursuits\n",
        "Running iterative hard thresholding\n",
        "12.8 0.0 23.4965768165\n",
        "12.8 9.49212589009e-18 23.4965768053\n",
        "Preconditioning matrix\n",
        "('ROWAVG: ', (971,))\n",
        "('X: ', (20, 971))\n",
        "Matching pursuits\n",
        "Running iterative hard thresholding\n",
        "12.8 0.0 23.4965768165\n",
        "12.8 1.01982815803e-17 23.4965768053\n",
        "Preconditioning matrix\n",
        "('ROWAVG: ', (971,))\n",
        "('X: ', (20, 971))\n",
        "Matching pursuits"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Running iterative hard thresholding\n",
        "12.8 0.0 23.4965768165\n",
        "12.8 1.05519180128e-17 23.4965768053\n",
        "Preconditioning matrix\n",
        "('ROWAVG: ', (971,))\n",
        "('X: ', (20, 971))\n",
        "Matching pursuits\n",
        "Running iterative hard thresholding\n",
        "12.8 0.0 23.4965768165\n",
        "12.8 1.08534500238e-17 23.4965768053\n",
        "Preconditioning matrix\n",
        "('ROWAVG: ', (971,))\n",
        "('X: ', (20, 971))\n",
        "Matching pursuits\n",
        "Running iterative hard thresholding\n",
        "12.8 0.0 23.4965768165\n",
        "12.8"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1.10893719083e-17 23.4965768053\n",
        "Preconditioning matrix\n",
        "('ROWAVG: ', (971,))\n",
        "('X: ', (20, 971))\n",
        "Matching pursuits\n",
        "Running iterative hard thresholding\n",
        "12.8 0.0 23.4965768165\n",
        "12.8 1.13050159733e-17 23.4965768053\n",
        "Preconditioning matrix\n",
        "('ROWAVG: ', (971,))\n",
        "('X: ', (20, 971))\n",
        "Matching pursuits\n",
        "Running iterative hard thresholding\n",
        "12.8 0.0 23.4965768165\n",
        "12.8 1.14825423851e-17 23.4965768053\n",
        "Preconditioning matrix\n",
        "('ROWAVG: ', (971,))\n",
        "('X: ', (20, 971))\n",
        "Matching pursuits"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Running iterative hard thresholding\n",
        "12.8 0.0 23.4965768165\n",
        "12.8 1.16068897475e-17 23.4965768053\n",
        "Preconditioning matrix\n",
        "('ROWAVG: ', (971,))\n",
        "('X: ', (20, 971))\n",
        "Matching pursuits\n",
        "Running iterative hard thresholding\n",
        "12.8 0.0 23.4965768165\n",
        "12.8 1.17275227303e-17 23.4965768053\n",
        "Preconditioning matrix\n",
        "('ROWAVG: ', (971,))\n",
        "('X: ', (20, 971))\n",
        "Matching pursuits\n",
        "Running iterative hard thresholding\n",
        "12.8 0.0 23.4965768165\n",
        "12.8 1.18376098888e-17 23.4965768053\n",
        "Preconditioning matrix"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('ROWAVG: ', (971,))\n",
        "('X: ', (20, 971))\n",
        "Matching pursuits\n",
        "Running iterative hard thresholding\n",
        "12.8 0.0 23.4965768165\n",
        "12.8 1.19250731027e-17 23.4965768053\n",
        "Preconditioning matrix\n",
        "('ROWAVG: ', (971,))\n",
        "('X: ', (20, 971))\n",
        "Matching pursuits\n",
        "Running iterative hard thresholding\n",
        "12.8 0.0 23.4965768165\n",
        "12.8 1.19945860481e-17 23.4965768053\n",
        "Preconditioning matrix\n",
        "('ROWAVG: ', (971,))\n",
        "('X: ', (20, 971))\n",
        "Matching pursuits"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Running iterative hard thresholding\n",
        "12.8 0.0 23.4965740077\n",
        "12.8 1.20519691901e-17 23.4965739965\n",
        "Preconditioning matrix\n",
        "('ROWAVG: ', (971,))\n",
        "('X: ', (20, 971))\n",
        "Matching pursuits\n",
        "Running iterative hard thresholding\n",
        "12.8 0.0 23.4965768165\n",
        "12.8 1.20967997956e-17 23.4965768053\n",
        "Preconditioning matrix\n",
        "('ROWAVG: ', (971,))\n",
        "('X: ', (20, 971))\n",
        "Matching pursuits\n",
        "Running iterative hard thresholding"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "12.8 0.0 23.4603258953\n",
        "12.8 1.21367252299e-17 23.4603258841\n",
        "Preconditioning matrix\n",
        "('ROWAVG: ', (971,))\n",
        "('X: ', (20, 971))\n",
        "Matching pursuits\n",
        "Running iterative hard thresholding\n",
        "12.8 0.0 23.4965768165\n",
        "12.8 1.21688121687e-17 23.4965768053\n",
        "Preconditioning matrix\n",
        "('ROWAVG: ', (971,))\n",
        "('X: ', (20, 971))\n",
        "Matching pursuits\n",
        "Running iterative hard thresholding"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "12.8 0.0 23.4965768165\n",
        "12.8 1.21913894641e-17 23.4965768053\n",
        "Preconditioning matrix\n",
        "('ROWAVG: ', (971,))\n",
        "('X: ', (20, 971))\n",
        "Matching pursuits\n",
        "Running iterative hard thresholding\n",
        "12.8 0.0 23.4965768165\n",
        "12.8 1.22111494253e-17 23.4965768053\n",
        "Preconditioning matrix\n",
        "('ROWAVG: ', (971,))\n",
        "('X: ', (20, 971))\n",
        "Matching pursuits\n",
        "Running iterative hard thresholding\n",
        "12.8 0.0 23.4965740077\n",
        "12.8"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1.22270465836e-17 23.4965739965\n",
        "Preconditioning matrix\n",
        "('ROWAVG: ', (971,))\n",
        "('X: ', (20, 971))\n",
        "Matching pursuits\n",
        "Running iterative hard thresholding\n",
        "12.8 0.0 23.4965768165\n",
        "12.8 1.22413672757e-17 23.4965768053\n",
        "Preconditioning matrix\n",
        "('ROWAVG: ', (971,))\n",
        "('X: ', (20, 971))\n",
        "Matching pursuits\n",
        "Running iterative hard thresholding\n",
        "12.8 0.0 23.4965768165\n",
        "12.8 1.22552812144e-17 23.4965768053\n",
        "Preconditioning matrix\n",
        "('ROWAVG: ', (971,))\n",
        "('X: ', (20, 971))\n",
        "Matching pursuits\n",
        "Running iterative hard thresholding"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "12.8 0.0 23.4965768165\n",
        "12.8 1.22689696521e-17 23.4965768053\n",
        "Preconditioning matrix\n",
        "('ROWAVG: ', (971,))\n",
        "('X: ', (20, 971))\n",
        "Matching pursuits\n",
        "Running iterative hard thresholding\n",
        "12.8 0.0 23.4965740077\n",
        "12.8 1.22819507803e-17 23.4965739965\n",
        "Preconditioning matrix\n",
        "('ROWAVG: ', (971,))\n",
        "('X: ', (20, 971))\n",
        "Matching pursuits\n",
        "Running iterative hard thresholding\n",
        "12.8 0.0 23.4965768165\n",
        "12.8 1.22945569913e-17 23.4965768053\n",
        "Preconditioning matrix\n",
        "('ROWAVG: ', (971,))\n",
        "('X: ', (20, 971))\n",
        "Matching pursuits\n",
        "Running iterative hard thresholding"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "12.8 0.0 23.4965768165\n",
        "12.8 1.23064852841e-17 23.4965768053\n",
        "Preconditioning matrix\n",
        "('ROWAVG: ', (971,))\n",
        "('X: ', (20, 971))\n",
        "Matching pursuits\n",
        "Running iterative hard thresholding\n",
        "12.8 0.0 23.4965768165\n",
        "12.8 1.23176869129e-17 23.4965768053\n",
        "Preconditioning matrix\n",
        "('ROWAVG: ', (971,))\n",
        "('X: ', (20, 971))\n",
        "Matching pursuits\n",
        "Running iterative hard thresholding\n",
        "12.8 0.0 23.4965740077\n",
        "12.8 1.23282030941e-17 23.4965739965\n",
        "Preconditioning matrix\n",
        "('ROWAVG: ', (971,))\n",
        "('X: ', (20, 971))\n",
        "Matching pursuits\n",
        "Running iterative hard thresholding"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "12.8 0.0 23.4965740077\n",
        "12.8 1.23385555821e-17 23.4965739965\n",
        "Preconditioning matrix\n",
        "('ROWAVG: ', (971,))\n",
        "('X: ', (20, 971))\n",
        "Matching pursuits\n",
        "Running iterative hard thresholding\n",
        "12.8 0.0 23.4965768165\n",
        "12.8 1.23487412325e-17 23.4965768053\n",
        "Preconditioning matrix\n",
        "('ROWAVG: ', (971,))\n",
        "('X: ', (20, 971))\n",
        "Matching pursuits\n",
        "Running iterative hard thresholding\n",
        "12.8 0.0 23.4965768165\n",
        "12.8 1.23588311833e-17 23.4965768053\n",
        "Preconditioning matrix\n",
        "('ROWAVG: ', (971,))\n",
        "('X: ', (20, 971))\n",
        "Matching pursuits\n",
        "Running iterative hard thresholding"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "12.8 0.0 23.4965768165\n",
        "12.8 1.23688855343e-17 23.4965768053\n",
        "Preconditioning matrix\n",
        "('ROWAVG: ', (971,))\n",
        "('X: ', (20, 971))\n",
        "Matching pursuits\n",
        "Running iterative hard thresholding\n",
        "12.8 0.0 23.4603258953\n",
        "12.8 1.23787761719e-17 23.4603258841\n",
        "Preconditioning matrix\n",
        "('ROWAVG: ', (971,))\n",
        "('X: ', (20, 971))\n",
        "Matching pursuits\n",
        "Running iterative hard thresholding\n",
        "12.8 0.0 23.4965740077\n",
        "12.8 1.23883252042e-17 23.4965739965\n",
        "Preconditioning matrix\n",
        "('ROWAVG: ', (971,))\n",
        "('X: ', (20, 971))\n",
        "Matching pursuits"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Running iterative hard thresholding\n",
        "12.8 0.0 23.4965768165\n",
        "12.8 1.23976529506e-17 23.4965768053\n",
        "Preconditioning matrix\n",
        "('ROWAVG: ', (971,))\n",
        "('X: ', (20, 971))\n",
        "Matching pursuits\n",
        "Running iterative hard thresholding\n",
        "12.8 0.0 23.4965768165\n",
        "12.8 1.24066600156e-17 23.4965768053\n",
        "Preconditioning matrix\n",
        "('ROWAVG: ', (971,))\n",
        "('X: ', (20, 971))\n",
        "Matching pursuits\n",
        "Running iterative hard thresholding\n",
        "12.8 0.0 23.4965768165\n",
        "12.8 1.24153459382e-17 23.4965768053\n",
        "Preconditioning matrix\n",
        "('ROWAVG: ', (971,))\n",
        "('X: ', (20, 971))\n",
        "Matching pursuits"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Running iterative hard thresholding\n",
        "12.8 0.0 23.4965768165\n",
        "12.8 1.24231779343e-17 23.4965768053\n",
        "Preconditioning matrix\n",
        "('ROWAVG: ', (971,))\n",
        "('X: ', (20, 971))\n",
        "Matching pursuits\n",
        "Running iterative hard thresholding\n",
        "12.8 0.0 23.4965768165\n",
        "12.8 1.24307693286e-17 23.4965768053\n",
        "Preconditioning matrix\n",
        "('ROWAVG: ', (971,))\n",
        "('X: ', (20, 971))\n",
        "Matching pursuits"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Running iterative hard thresholding\n",
        "12.8 0.0 23.4965768165\n",
        "12.8 1.24383458427e-17 23.4965768053\n",
        "Preconditioning matrix\n",
        "('ROWAVG: ', (971,))\n",
        "('X: ', (20, 971))\n",
        "Matching pursuits\n",
        "Running iterative hard thresholding\n",
        "12.8 0.0 23.4965768165\n",
        "12.8 1.24458936376e-17 23.4965768053\n",
        "Preconditioning matrix\n",
        "('ROWAVG: ', (971,))\n",
        "('X: ', (20, 971))\n",
        "Matching pursuits\n",
        "Running iterative hard thresholding\n",
        "12.8 0.0 23.4965768165\n",
        "12.8 1.2453427772e-17 23.4965768053\n",
        "Preconditioning matrix"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('ROWAVG: ', (971,))\n",
        "('X: ', (20, 971))\n",
        "Matching pursuits\n",
        "Running iterative hard thresholding\n",
        "12.8 0.0 23.4965768165\n",
        "12.8 1.24609294415e-17 23.4965768053\n",
        "Preconditioning matrix\n",
        "('ROWAVG: ', (971,))\n",
        "('X: ', (20, 971))\n",
        "Matching pursuits\n",
        "Running iterative hard thresholding\n",
        "12.8 0.0 23.4965768165\n",
        "12.8 1.24683927571e-17 23.4965768053\n",
        "Preconditioning matrix\n",
        "('ROWAVG: ', (971,))\n",
        "('X: ', (20, 971))\n",
        "Matching pursuits\n",
        "Running iterative hard thresholding"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "12.8 0.0 23.4965768165\n",
        "12.8 1.24758304174e-17 23.4965768053\n",
        "Preconditioning matrix\n",
        "('ROWAVG: ', (971,))\n",
        "('X: ', (20, 971))\n",
        "Matching pursuits\n",
        "Running iterative hard thresholding\n",
        "12.8 0.0 23.4965768165\n",
        "12.8 1.24832479508e-17 23.4965768053\n",
        "Preconditioning matrix\n",
        "('ROWAVG: ', (971,))\n",
        "('X: ', (20, 971))\n",
        "Matching pursuits\n",
        "Running iterative hard thresholding\n",
        "12.8 0.0 23.4965768165\n",
        "12.8 1.24906223137e-17 23.4965768053\n",
        "Preconditioning matrix\n",
        "('ROWAVG: ', (971,))\n",
        "('X: ', (20, 971))\n",
        "Matching pursuits\n",
        "Running iterative hard thresholding"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "12.8 0.0 23.4965768165\n",
        "12.8 1.24979213797e-17 23.4965768053\n",
        "Preconditioning matrix\n",
        "('ROWAVG: ', (971,))\n",
        "('X: ', (20, 971))\n",
        "Matching pursuits\n",
        "Running iterative hard thresholding\n",
        "12.8 0.0 23.4965768165\n",
        "12.8 1.25051063135e-17 23.4965768053\n",
        "Preconditioning matrix\n",
        "('ROWAVG: ', (971,))\n",
        "('X: ', (20, 971))\n",
        "Matching pursuits\n",
        "Running iterative hard thresholding\n",
        "12.8 0.0 23.4965768165\n",
        "12.8 1.25122506471e-17 23.4965768053\n",
        "Preconditioning matrix\n",
        "('ROWAVG: ', (971,))\n",
        "('X: ', (20, 971))\n",
        "Matching pursuits\n",
        "Running iterative hard thresholding"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "12.8 0.0 23.4965768165\n",
        "12.8 1.25193326319e-17 23.4965768053\n",
        "Preconditioning matrix\n",
        "('ROWAVG: ', (971,))\n",
        "('X: ', (20, 971))\n",
        "Matching pursuits\n",
        "Running iterative hard thresholding\n",
        "12.8 0.0 23.4965768165\n",
        "12.8 1.25263340748e-17 23.4965768053\n",
        "Preconditioning matrix\n",
        "('ROWAVG: ', (971,))\n",
        "('X: ', (20, 971))\n",
        "Matching pursuits\n",
        "Running iterative hard thresholding\n",
        "12.8 0.0 23.4965768165\n",
        "12.8 1.25332668976e-17 23.4965768053\n"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "####################################################################################\n",
      "# Sorts words by their weights of the above computed portion                       #\n",
      "####################################################################################\n",
      "\n",
      "print(\"-------------------------------------------\")\n",
      "print(\"| IHT Keywords                            |\")\n",
      "print(\"-------------------------------------------\")\n",
      "for index,weight in enumerate(IHT_weights):\n",
      "    all_terms = [(x, weight[i]) for i, x in enumerate(features)]\n",
      "    all_terms.sort(key=lambda x: x[1], reverse=True)\n",
      "    print([x[0] for x in all_terms[:20]])\n",
      "    \n",
      "print(\"-------------------------------------------\")\n",
      "print(\"| Lasso Keywords                           |\")\n",
      "print(\"-------------------------------------------\")\n",
      "for index, weights in enumerate(lasso_weights):\n",
      "    all_terms = [(x, weights[i]) for i, x in enumerate(features)]\n",
      "    all_terms.sort(key=lambda x: x[1], reverse=True)\n",
      "    print([x[0] for x in all_terms[:20]])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "-------------------------------------------\n",
        "| IHT Keywords                            |\n",
        "-------------------------------------------\n",
        "[u'plus', u'advantage', u'absent', u'academic', u'accident', u'accused', u'achievement', u'act', u'acting', u'action', u'actor', u'actually', u'add', u'added', u'adore', u'adult', u'affinity', u'afraid', u'age', u'agent']\n",
        "[u'plus', u'advantage', u'absent', u'academic', u'accident', u'accused', u'achievement', u'act', u'acting', u'action', u'actor', u'actually', u'add', u'added', u'adore', u'adult', u'affinity', u'afraid', u'age', u'agent']\n",
        "[u'plus', u'advantage', u'absent', u'academic', u'accident', u'accused', u'achievement', u'act', u'acting', u'action', u'actor', u'actually', u'add', u'added', u'adore', u'adult', u'affinity', u'afraid', u'age', u'agent']\n",
        "[u'plus', u'advantage', u'absent', u'academic', u'accident', u'accused', u'achievement', u'act', u'acting', u'action', u'actor', u'actually', u'add', u'added', u'adore', u'adult', u'affinity', u'afraid', u'age', u'agent']\n",
        "[u'plus', u'advantage', u'absent', u'academic', u'accident', u'accused', u'achievement', u'act', u'acting', u'action', u'actor', u'actually', u'add', u'added', u'adore', u'adult', u'affinity', u'afraid', u'age', u'agent']\n",
        "[u'plus', u'advantage', u'absent', u'academic', u'accident', u'accused', u'achievement', u'act', u'acting', u'action', u'actor', u'actually', u'add', u'added', u'adore', u'adult', u'affinity', u'afraid', u'age', u'agent']\n",
        "[u'plus', u'advantage', u'absent', u'academic', u'accident', u'accused', u'achievement', u'act', u'acting', u'action', u'actor', u'actually', u'add', u'added', u'adore', u'adult', u'afraid', u'age', u'agent', u'ago']\n",
        "[u'plus', u'advantage', u'absent', u'academic', u'accident', u'accused', u'achievement', u'act', u'acting', u'action', u'actor', u'actually', u'add', u'added', u'adore', u'adult', u'afraid', u'age', u'agent', u'ago']\n",
        "[u'plus', u'advantage', u'absent', u'academic', u'accident', u'accused', u'achievement', u'act', u'acting', u'action', u'actor', u'actually', u'add', u'added', u'adore', u'adult', u'affinity', u'afraid', u'age', u'agent']\n",
        "[u'plus', u'advantage', u'absent', u'academic', u'accident', u'accused', u'achievement', u'act', u'acting', u'action', u'actor', u'actually', u'add', u'added', u'adore', u'adult', u'afraid', u'age', u'agent', u'ago']\n",
        "[u'plus', u'advantage', u'absent', u'academic', u'accident', u'accused', u'achievement', u'act', u'acting', u'action', u'actor', u'actually', u'add', u'added', u'adore', u'adult', u'afraid', u'age', u'agent', u'ago']\n",
        "[u'plus', u'advantage', u'absent', u'academic', u'accident', u'accused', u'achievement', u'act', u'acting', u'action', u'actor', u'actually', u'add', u'added', u'adore', u'adult', u'afraid', u'age', u'agent', u'ago']\n",
        "[u'plus', u'advantage', u'absent', u'academic', u'accident', u'accused', u'achievement', u'act', u'acting', u'action', u'actor', u'actually', u'add', u'added', u'adore', u'adult', u'afraid', u'age', u'agent', u'ago']\n",
        "[u'plus', u'advantage', u'absent', u'academic', u'accident', u'accused', u'achievement', u'act', u'acting', u'action', u'actor', u'actually', u'add', u'added', u'adore', u'adult', u'afraid', u'age', u'agent', u'ago']\n",
        "[u'plus', u'advantage', u'absent', u'academic', u'accident', u'accused', u'achievement', u'act', u'acting', u'action', u'actor', u'actually', u'add', u'added', u'adore', u'adult', u'afraid', u'age', u'agent', u'ago']\n",
        "[u'plus', u'advantage', u'absent', u'academic', u'accident', u'accused', u'achievement', u'act', u'acting', u'action', u'actor', u'actually', u'add', u'added', u'adore', u'adult', u'afraid', u'age', u'agent', u'ago']\n",
        "[u'plus', u'advantage', u'absent', u'academic', u'accident', u'accused', u'achievement', u'act', u'acting', u'action', u'actor', u'actually', u'add', u'added', u'adore', u'adult', u'afraid', u'age', u'agent', u'ago']\n",
        "[u'plus', u'advantage', u'absent', u'academic', u'accident', u'accused', u'achievement', u'act', u'acting', u'action', u'actor', u'actually', u'add', u'added', u'adore', u'adult', u'afraid', u'age', u'agent', u'ago']\n",
        "[u'plus', u'advantage', u'absent', u'academic', u'accident', u'accused', u'achievement', u'act', u'acting', u'action', u'actor', u'actually', u'add', u'added', u'adore', u'adult', u'afraid', u'age', u'agent', u'ago']\n",
        "[u'plus', u'advantage', u'absent', u'academic', u'accident', u'accused', u'achievement', u'act', u'acting', u'action', u'actor', u'actually', u'add', u'added', u'adore', u'adult', u'afraid', u'age', u'agent', u'ago']\n",
        "[u'plus', u'advantage', u'absent', u'academic', u'accident', u'accused', u'achievement', u'act', u'acting', u'action', u'actor', u'actually', u'add', u'added', u'adore', u'adult', u'afraid', u'age', u'agent', u'ago']\n",
        "[u'plus', u'advantage', u'absent', u'academic', u'accident', u'accused', u'achievement', u'act', u'acting', u'action', u'actor', u'actually', u'add', u'added', u'adore', u'adult', u'afraid', u'age', u'agent', u'ago']\n",
        "[u'plus', u'advantage', u'movie', u'absent', u'academic', u'accident', u'accused', u'achievement', u'act', u'acting', u'action', u'actor', u'actually', u'add', u'added', u'adore', u'adult', u'afraid', u'age', u'agent']\n",
        "[u'plus', u'advantage', u'movie', u'film', u'absent', u'academic', u'accident', u'accused', u'achievement', u'act', u'acting', u'action', u'actor', u'actually', u'add', u'added', u'adore', u'adult', u'afraid', u'age']\n",
        "[u'plus', u'advantage', u'movie', u'film', u'bad', u'absent', u'academic', u'accident', u'accused', u'achievement', u'act', u'acting', u'action', u'actor', u'actually', u'add', u'added', u'adore', u'adult', u'afraid']\n",
        "[u'plus', u'advantage', u'movie', u'film', u'bad', u'absent', u'academic', u'accident', u'accused', u'achievement', u'act', u'acting', u'action', u'actor', u'actually', u'add', u'added', u'adore', u'adult', u'afraid']\n",
        "[u'plus', u'advantage', u'movie', u'film', u'bad', u'absent', u'academic', u'accident', u'accused', u'achievement', u'act', u'acting', u'action', u'actor', u'actually', u'add', u'added', u'adore', u'adult', u'afraid']\n",
        "[u'plus', u'advantage', u'movie', u'film', u'bad', u'cast', u'little', u'absent', u'academic', u'accident', u'accused', u'achievement', u'act', u'acting', u'action', u'actor', u'actually', u'add', u'added', u'adore']\n",
        "[u'plus', u'advantage', u'movie', u'film', u'bad', u'cast', u'little', u'absent', u'academic', u'accident', u'accused', u'achievement', u'act', u'acting', u'action', u'actor', u'actually', u'add', u'added', u'adore']\n",
        "[u'plus', u'advantage', u'movie', u'film', u'bad', u'cast', u'little', u'real', u'story', u'goes', u'absent', u'academic', u'accident', u'accused', u'achievement', u'act', u'acting', u'action', u'actor', u'actually']\n",
        "[u'plus', u'advantage', u'movie', u'film', u'bad', u'cast', u'little', u'real', u'story', u'goes', u'probably', u'hard', u'people', u'absent', u'academic', u'accident', u'accused', u'achievement', u'act', u'acting']"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[u'plus', u'advantage', u'movie', u'film', u'bad', u'cast', u'little', u'real', u'story', u'goes', u'probably', u'hard', u'people', u'audience', u'script', u'absent', u'academic', u'accident', u'accused', u'achievement']\n",
        "[u'plus', u'advantage', u'movie', u'film', u'bad', u'cast', u'little', u'real', u'story', u'goes', u'probably', u'hard', u'people', u'audience', u'script', u'world', u'couple', u'mother', u'absent', u'academic']\n",
        "[u'plus', u'advantage', u'movie', u'film', u'bad', u'cast', u'little', u'real', u'story', u'goes', u'probably', u'hard', u'people', u'audience', u'script', u'world', u'couple', u'mother', u'soon', u'figure']\n",
        "[u'plus', u'advantage', u'movie', u'film', u'bad', u'cast', u'little', u'real', u'story', u'goes', u'probably', u'hard', u'people', u'audience', u'script', u'world', u'couple', u'mother', u'soon', u'figure']\n",
        "[u'plus', u'advantage', u'movie', u'film', u'bad', u'cast', u'little', u'real', u'story', u'goes', u'probably', u'hard', u'people', u'audience', u'script', u'world', u'couple', u'mother', u'soon', u'figure']\n",
        "[u'plus', u'advantage', u'movie', u'film', u'bad', u'cast', u'little', u'real', u'story', u'goes', u'probably', u'hard', u'people', u'audience', u'script', u'world', u'couple', u'mother', u'soon', u'figure']\n",
        "[u'plus', u'advantage', u'movie', u'film', u'bad', u'cast', u'little', u'real', u'story', u'goes', u'probably', u'hard', u'people', u'audience', u'script', u'world', u'couple', u'mother', u'soon', u'figure']\n",
        "[u'plus', u'advantage', u'movie', u'film', u'bad', u'cast', u'little', u'real', u'story', u'goes', u'probably', u'hard', u'people', u'audience', u'script', u'world', u'couple', u'mother', u'soon', u'figure']\n",
        "[u'plus', u'advantage', u'movie', u'film', u'bad', u'cast', u'little', u'real', u'story', u'goes', u'probably', u'hard', u'people', u'audience', u'script', u'world', u'couple', u'mother', u'soon', u'figure']\n",
        "[u'plus', u'advantage', u'movie', u'film', u'bad', u'cast', u'little', u'real', u'story', u'goes', u'probably', u'hard', u'people', u'audience', u'script', u'world', u'couple', u'mother', u'soon', u'figure']\n",
        "[u'plus', u'advantage', u'movie', u'film', u'bad', u'cast', u'little', u'real', u'story', u'goes', u'probably', u'hard', u'people', u'audience', u'script', u'world', u'couple', u'mother', u'soon', u'figure']\n",
        "[u'plus', u'advantage', u'movie', u'film', u'bad', u'cast', u'little', u'real', u'story', u'goes', u'probably', u'hard', u'people', u'audience', u'script', u'world', u'couple', u'mother', u'soon', u'figure']\n",
        "[u'plus', u'advantage', u'movie', u'film', u'bad', u'cast', u'little', u'real', u'story', u'goes', u'probably', u'hard', u'people', u'audience', u'script', u'world', u'couple', u'mother', u'soon', u'figure']\n",
        "[u'plus', u'advantage', u'movie', u'film', u'bad', u'cast', u'little', u'real', u'story', u'goes', u'probably', u'hard', u'people', u'audience', u'script', u'world', u'couple', u'mother', u'soon', u'figure']\n",
        "[u'plus', u'advantage', u'movie', u'film', u'bad', u'cast', u'little', u'real', u'story', u'goes', u'probably', u'hard', u'people', u'audience', u'script', u'world', u'couple', u'mother', u'soon', u'figure']\n",
        "[u'plus', u'advantage', u'movie', u'film', u'bad', u'cast', u'little', u'real', u'story', u'goes', u'probably', u'hard', u'people', u'audience', u'script', u'world', u'couple', u'mother', u'soon', u'figure']\n",
        "[u'plus', u'advantage', u'movie', u'film', u'bad', u'cast', u'little', u'real', u'story', u'goes', u'probably', u'hard', u'people', u'audience', u'script', u'world', u'couple', u'mother', u'soon', u'figure']\n",
        "[u'plus', u'advantage', u'movie', u'film', u'bad', u'cast', u'little', u'real', u'story', u'goes', u'probably', u'hard', u'people', u'audience', u'script', u'world', u'couple', u'mother', u'soon', u'figure']\n",
        "[u'plus', u'advantage', u'movie', u'film', u'bad', u'cast', u'little', u'real', u'story', u'goes', u'probably', u'hard', u'people', u'audience', u'script', u'world', u'couple', u'mother', u'soon', u'figure']\n",
        "[u'plus', u'advantage', u'movie', u'film', u'bad', u'cast', u'little', u'real', u'story', u'goes', u'probably', u'hard', u'people', u'audience', u'script', u'world', u'couple', u'mother', u'soon', u'figure']\n",
        "[u'plus', u'advantage', u'movie', u'film', u'bad', u'cast', u'little', u'real', u'story', u'goes', u'probably', u'hard', u'people', u'audience', u'script', u'world', u'couple', u'mother', u'soon', u'figure']\n",
        "[u'plus', u'advantage', u'movie', u'film', u'bad', u'cast', u'little', u'real', u'story', u'goes', u'probably', u'hard', u'people', u'audience', u'script', u'world', u'couple', u'mother', u'soon', u'figure']\n",
        "[u'plus', u'advantage', u'movie', u'film', u'bad', u'cast', u'little', u'real', u'story', u'goes', u'probably', u'hard', u'people', u'audience', u'script', u'world', u'couple', u'mother', u'soon', u'figure']\n",
        "[u'plus', u'advantage', u'movie', u'film', u'bad', u'cast', u'little', u'real', u'story', u'goes', u'probably', u'hard', u'people', u'audience', u'script', u'world', u'couple', u'mother', u'soon', u'figure']\n",
        "[u'plus', u'advantage', u'movie', u'film', u'bad', u'cast', u'little', u'real', u'story', u'goes', u'probably', u'hard', u'people', u'audience', u'script', u'world', u'couple', u'mother', u'soon', u'figure']\n",
        "[u'plus', u'advantage', u'movie', u'film', u'bad', u'cast', u'little', u'real', u'story', u'goes', u'probably', u'hard', u'people', u'audience', u'script', u'world', u'couple', u'mother', u'soon', u'figure']\n",
        "[u'plus', u'advantage', u'movie', u'film', u'bad', u'cast', u'little', u'real', u'story', u'goes', u'probably', u'hard', u'people', u'audience', u'script', u'world', u'couple', u'mother', u'soon', u'figure']\n",
        "[u'plus', u'advantage', u'movie', u'film', u'bad', u'cast', u'little', u'real', u'story', u'goes', u'probably', u'hard', u'people', u'audience', u'script', u'world', u'couple', u'mother', u'soon', u'figure']\n",
        "[u'plus', u'advantage', u'movie', u'film', u'bad', u'cast', u'little', u'real', u'story', u'goes', u'probably', u'hard', u'people', u'audience', u'script', u'world', u'couple', u'mother', u'soon', u'figure']\n",
        "[u'plus', u'advantage', u'movie', u'film', u'bad', u'cast', u'little', u'real', u'story', u'goes', u'probably', u'hard', u'people', u'audience', u'script', u'world', u'couple', u'mother', u'soon', u'figure']\n",
        "[u'plus', u'advantage', u'movie', u'film', u'bad', u'cast', u'little', u'real', u'story', u'goes', u'probably', u'hard', u'people', u'audience', u'script', u'world', u'couple', u'mother', u'soon', u'figure']\n",
        "[u'plus', u'advantage', u'movie', u'film', u'bad', u'cast', u'little', u'real', u'story', u'goes', u'probably', u'hard', u'people', u'audience', u'script', u'world', u'couple', u'mother', u'soon', u'figure']\n",
        "[u'plus', u'advantage', u'movie', u'film', u'bad', u'cast', u'little', u'real', u'story', u'goes', u'probably', u'hard', u'people', u'audience', u'script', u'world', u'couple', u'mother', u'soon', u'figure']\n",
        "-------------------------------------------\n",
        "| Lasso Keywords                           |\n",
        "-------------------------------------------\n",
        "[u'gerard', u'dora', u'billie', u'dice', u'glitter', u'fugitive', u'sam', u'various', u'warner', u'dramatic', u'period', u'spice', u'suffer', u'loser', u'love', u'doing', u'john', u'star', u'kate', u'plus']"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[u'gerard', u'dora', u'billie', u'fugitive', u'dice', u'glitter', u'sam', u'various', u'warner', u'dramatic', u'period', u'spice', u'suffer', u'love', u'loser', u'star', u'doing', u'kate', u'plus', u'drive']\n",
        "[u'gerard', u'dora', u'fugitive', u'sam', u'various', u'warner', u'billie', u'loser', u'dice', u'glitter', u'plus', u'goth', u'john', u'anonymous', u'contact', u'factual', u'jacob', u'jones', u'lay', u'marie']"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[u'gerard', u'dora', u'fugitive', u'sam', u'various', u'warner', u'loser', u'plus', u'goth', u'anonymous', u'contact', u'factual', u'jacob', u'jones', u'lay', u'marie', u'marshal', u'tommy', u'unrelated', u'paul']\n",
        "[u'dora', u'gerard', u'fugitive', u'sam', u'various', u'warner', u'loser', u'goth', u'plus', u'anonymous', u'contact', u'factual', u'jacob', u'jones', u'lay', u'marie', u'marshal', u'tommy', u'unrelated', u'aside']"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[u'dora', u'gerard', u'fugitive', u'loser', u'sam', u'various', u'warner', u'goth', u'plus', u'aside', u'fast', u'jason', u'anonymous', u'contact', u'factual', u'jacob', u'jones', u'lay', u'marie', u'marshal']\n",
        "[u'dora', u'loser', u'goth', u'aside', u'fast', u'jason', u'advantage', u'affinity', u'bound', u'comeuppance', u'continually', u'covering', u'cultural', u'edward', u'erratically', u'european', u'geriatric', u'hero', u'instance', u'met']"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[u'dora', u'gerard', u'fugitive', u'loser', u'sam', u'various', u'warner', u'goth', u'plus', u'aside', u'fast', u'jason', u'anonymous', u'contact', u'factual', u'jacob', u'jones', u'lay', u'marie', u'marshal']\n",
        "[u'altogether', u'chair', u'debi', u'diaphragm', u'displeasure', u'downright', u'eagerly', u'form', u'grandmother', u'hole', u'ill', u'jane', u'mouth', u'normally', u'nudity', u'praying', u'preceding', u'psychological', u'romp', u'welcome']"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[u'hush', u'helen', u'rodman', u'martha', u'double', u'matchmaker', u'dennis', u'dance', u'irish', u'kill', u'screenplay', u'result', u'son', u'nell', u'mickey', u'woman', u'darby', u'horse', u'jessica', u'johnathan']\n"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}